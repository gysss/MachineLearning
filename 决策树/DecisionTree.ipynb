{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speal length</th>\n",
       "      <th>speal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speal length  speal width  petal length  petal width  label\n",
       "0           5.1          3.5           1.4          0.2      0\n",
       "1           4.9          3.0           1.4          0.2      0\n",
       "2           4.7          3.2           1.3          0.2      0\n",
       "3           4.6          3.1           1.5          0.2      0\n",
       "4           5.0          3.6           1.4          0.2      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['label'] = iris.target\n",
    "df.columns = ['speal length', 'speal width', 'petal length', 'petal width', 'label']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3/C4.5算法实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = np.array(df)\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义计算熵公式的函数\n",
    "def calcEntropy(target):\n",
    "    label = np.unique(target)\n",
    "    n = label.size\n",
    "    count = np.zeros(n)\n",
    "    p_i = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        count[i] = target[target == label[i]].size\n",
    "    \n",
    "    # 计算每个类别的概率\n",
    "    p_i = np.divide(count, target.size)\n",
    "    \n",
    "    # 计算熵\n",
    "    entropy = 0\n",
    "    for i in range(n):\n",
    "        entropy = entropy - p_i[i] * np.log2(p_i[i])\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.582879624786234"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dataset = calcEntropy(y_train)\n",
    "ent_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义二分类条件熵公式的函数，把属性的值分为两类\n",
    "# 对于花瓣宽度来说: 一类是大于 0.8， 另一类就是小于等于 0.8\n",
    "def calcConditionEntropy(feature, condition, target, ways = 'ID3'):\n",
    "    true_condition = condition(feature)\n",
    "    false_condition = true_condition == False\n",
    "    target_true = target[true_condition]\n",
    "    target_false = target[false_condition]\n",
    "    # 每种属性类别的数量除以总数就计算出其概率\n",
    "    p_true = target_true.size / target.size\n",
    "    p_false = 1 - p_true\n",
    "    # 每种属性类别的概率乘以该类别下的信息熵\n",
    "    entropy = p_true * calcEntropy(target_true) + p_false * calcEntropy(target_false)\n",
    "    # 信息增益\n",
    "    entropy = ent_dataset - entropy\n",
    "    if ways == 'C4.5':\n",
    "        H = calcEntropy(true_condition)\n",
    "        if(H != 0):\n",
    "            entropy = entropy / H\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999999989"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petal_width = X_train[:, 3]\n",
    "HC = calcConditionEntropy(petal_width, lambda feature:feature<0.8, y_train, 'C4.5')\n",
    "HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_points(feature, target):\n",
    "    \"\"\"\n",
    "    生成特征的所有分界点: 先对特征进行排序，然后将 target 有变动的地方作为分界点\n",
    "    :param feature: 一维数组，一个特征的样本数据\n",
    "    :param target: 一维数组，数字或者字符串的分类标签\n",
    "    :return: 包含所有分界点的一维数组\n",
    "    \"\"\"\n",
    "    argsort = feature.argsort()\n",
    "    f1 = feature[argsort]\n",
    "    t1 = target[argsort]\n",
    "    \n",
    "    last_value = target[0]\n",
    "    split_value = []\n",
    "    \n",
    "    # 找出所有分裂点\n",
    "    for i in range(t1.size):\n",
    "        if last_value != t1[i]:\n",
    "            split_value.append((f1[i] + f1[i - 1]) / 2)\n",
    "            last_value = t1[i]\n",
    "\n",
    "    return np.array(split_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feature_entropy(feature, target, ways = 'ID3'):\n",
    "    \"\"\"\n",
    "    计算一个特征的所有分界点的条件熵，返回最小的那个条件熵（条件熵越小，信息增益越大）\n",
    "    :param feature: 一维数组，一个特征的样本数据\n",
    "    :param target: 一维数组，数字或者字符串的分类标签\n",
    "    :return: 分界点和条件熵\n",
    "    \"\"\"\n",
    "    max_ent_gain = 0\n",
    "    max_point = 0\n",
    "    \n",
    "    points = generate_feature_points(feature, target)\n",
    "    for p in points:\n",
    "        entropy = calcConditionEntropy(feature, lambda f: f < p, target, ways)\n",
    "        if entropy > max_ent_gain:\n",
    "            max_ent_gain = entropy\n",
    "            max_point = p\n",
    "\n",
    "    '没有分界点说明只有一类数据标签，熵为0'\n",
    "    if points.size == 0:\n",
    "        max_entropy = ent_dataset\n",
    "\n",
    "    return max_point, max_ent_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80000000000000004, 0.99999999999999989)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_feature_entropy(X_train[:, 3], y_train, 'C4.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature(features, target, ways = 'ID3'):\n",
    "    \"\"\"\n",
    "    从所有特征中选择出条件熵最小的特征（即最大增益）\n",
    "    :param features: 二维数据，包含所有特征的样本数据\n",
    "    :param target: 一维数组，数字或者字符串的分类标签\n",
    "    :return: 特征索引，条件熵，特征分界点\n",
    "    \"\"\"\n",
    "    max_ent_gain = 0\n",
    "    max_point = 0\n",
    "    num = features.shape[1]\n",
    "    index = 0\n",
    "    for i in range(num):\n",
    "        point, entropy = calc_feature_entropy(features[:, i], target, ways)\n",
    "        if entropy > max_ent_gain:\n",
    "            index = i\n",
    "            max_point = point\n",
    "            max_ent_gain = entropy\n",
    "\n",
    "    return index, max_point, max_ent_gain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2.4500000000000002, 0.99999999999999989)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_feature(X_train, y_train, 'C4.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    idn = 0\n",
    "    feature_index = ''\n",
    "    feature_point = 0\n",
    "    feature_entropy = 0\n",
    "    target_label = ''\n",
    "    true_node = None\n",
    "    false_node = None\n",
    "\n",
    "    @staticmethod\n",
    "    def decision(feature, point):\n",
    "        return feature < point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(features, target, idn, ways = 'ID3'):\n",
    "    \"\"\"\n",
    "    递归构建决策树\n",
    "    :param features: 二维数据，包含所有特征的样本数据\n",
    "    :param target: 一维数组，数字或者字符串的分类标签\n",
    "    :param idn: 决策树节点 id，通过 id 观察决策树计算过程\n",
    "    :return: 决策树根节点\n",
    "    \"\"\"\n",
    "    node = TreeNode()\n",
    "    \n",
    "    '1,若D中实例属于同一类Ck，则T为单节点树，并将类Ck作为结点的类标记，返回T'\n",
    "    if np.sum(target == target[0]) == len(target):\n",
    "        node.target_label = target[0]\n",
    "        return node\n",
    "    \n",
    "    ' 若A为空，则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T'\n",
    "    if len(features) == 0:\n",
    "        node.target_label = target[np.argmax(np.bincount(target))]\n",
    "        return node\n",
    "\n",
    "    '选择信息增益最大的特征'\n",
    "    index, point, entropy = select_feature(features, target, ways)\n",
    "    node.idn = idn\n",
    "    node.feature_index = index\n",
    "    node.feature_point = point\n",
    "    node.feature_entropy = entropy\n",
    "    '取出现次数最多的标签作为该特征节点的输出'\n",
    "    node.target_label = target[np.argmax(np.bincount(target))]\n",
    "\n",
    "#     print('build tree node id %d, index %d, point %f, entropy %f, label %s ' %\n",
    "#           (idn, index, point, entropy, node.target_label))\n",
    "\n",
    "    '熵小于 0.1 时则结束创建子节点，防止过拟合'\n",
    "    if entropy < 0.1:\n",
    "#         print('too low entropy : ', entropy)\n",
    "        return node\n",
    "\n",
    "    f_copy = features.copy()\n",
    "    t_copy = target.copy()\n",
    "    f = f_copy[:, index]\n",
    "    selector = node.decision(f, point)\n",
    "\n",
    "    '创建左右两个子节点'\n",
    "    idn = idn + 1\n",
    "    node.true_node = build_tree(f_copy[selector, :], t_copy[selector], idn, ways)\n",
    "    idn = node.true_node.idn + 1\n",
    "    node.false_node = build_tree(f_copy[selector == False], t_copy[selector == False], idn, ways)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, y_test, node):\n",
    "    score = 0\n",
    "    length = len(y_test)\n",
    "    for i in range(length):\n",
    "        p = node\n",
    "        while p.true_node or p.false_node:\n",
    "            if X_test[i][p.feature_index] < p.feature_point:\n",
    "                p = p.true_node\n",
    "            else:\n",
    "                p = p.false_node\n",
    "        if p.target_label == y_test[i]:\n",
    "            score += 1\n",
    "    return score/float(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node = build_tree(X_train, y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_test, y_test, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2 = build_tree(X_train, y_train, 1, 'C4.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_test, y_test, node2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
